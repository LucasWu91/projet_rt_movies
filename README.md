#  Scraping des films Rotten Tomatoes 2025 & Dashboard interactif

##  PrÃ©sentation du projet

Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre du module de Data Engineering.
L'objectif Ã©tait de construire une chaÃ®ne complÃ¨te de traitement de donnÃ©es, depuis la rÃ©cupÃ©ration des informations sur un site web jusqu'Ã  leur visualisation dans une application web.

Pour cela, j'ai choisi de travailler sur le site Rotten Tomatoes en rÃ©cupÃ©rant les films sortis en 2025 ainsi que leurs scores critiques et spectateurs.

Le projet repose sur trois Ã©tapes principales :
scraper les donnÃ©es, les stocker dans une base de donnÃ©es, puis les afficher via un dashboard interactif.

---

## ï¸ DÃ©marche et choix techniques

J'ai utilisÃ© Scrapy pour rÃ©aliser le scraping car il permet de structurer proprement le code et de parcourir facilement un grand nombre de pages.
Le spider rÃ©cupÃ¨re d'abord la liste des films 2025, puis visite chaque page individuelle afin d'extraire les informations importantes comme le titre, le score critique (Tomatometer) et le score des spectateurs (Audience Score).

Les donnÃ©es sont ensuite stockÃ©es dans une base MongoDB.
Ce choix s'est imposÃ© naturellement car MongoDB est trÃ¨s bien adaptÃ© aux donnÃ©es issues du web scraping, qui sont souvent semi-structurÃ©es et Ã©volutives.

Pour la partie visualisation, j'ai dÃ©veloppÃ© une application web en Python avec Flask.
Le backend se connecte Ã  MongoDB pour rÃ©cupÃ©rer les donnÃ©es et les transmettre au frontend, qui affiche des graphiques et une liste des films.

Enfin, l'ensemble du projet a Ã©tÃ© conteneurisÃ© avec Docker afin de pouvoir Ãªtre lancÃ© facilement sur n'importe quelle machine.

---

## ï¸ Architecture du projet

Le projet fonctionne selon un flux simple :

Le scraper collecte les donnÃ©es â†’ les enregistre dans MongoDB â†’ le dashboard lit la base â†’ les donnÃ©es sont affichÃ©es dans l'interface web.

Trois conteneurs sont utilisÃ©s :

* MongoDB (base de donnÃ©es)
* Scraper (Scrapy)
* Dashboard (Flask + JavaScript)

```
projet_rt_movies/
â”‚
â”œâ”€â”€ dashboard/
â”‚   â”œâ”€â”€ app.py                # Application web Flask/Dash
â”‚   â”œâ”€â”€ requirements.txt      # DÃ©pendances Python du dashboard
â”‚   â”œâ”€â”€ static/
â”‚   â”‚   â”œâ”€â”€ styles.css        # Styles CSS
â”‚   â”‚   â””â”€â”€ app.js            # Scripts JS (Plotly, interactions)
â”‚   â””â”€â”€ templates/
â”‚       â””â”€â”€ index.html        # Page principale
â”‚
â”œâ”€â”€ scraper/
â”‚   â””â”€â”€ spiders/
â”‚       â””â”€â”€ movies_2025.py    # Spider Scrapy Rotten Tomatoes
â”‚
â”œâ”€â”€ docs/
â”‚   â””â”€â”€ images/               # Captures d'Ã©cran du dashboard
â”‚
â”œâ”€â”€ docker-compose.yml        # Orchestration des containers
â”œâ”€â”€ requirements.txt          # DÃ©pendances globales
â””â”€â”€ README.md                 # Documentation du projet
```

---

##  Comment lancer le projet

### 1. Cloner le repository

```bash
git clone https://github.com/LucasWu91/projet_rt_movies.git
cd projet_rt_movies
```

### 2. ï¸ VÃ©rifier la structure

```bash
ls
```

Vous devriez voir :

```
dashboard/
scraper/
docker-compose.yml
requirements.txt
README.md
```

### 3. PrÃ©requis

Installer :

* Docker Desktop
* Git

Une fois Docker installÃ©, il suffit de se placer Ã  la racine du projet et d'exÃ©cuter :

```bash
docker compose up --build
```

Cette commande lance automatiquement :

* la base de donnÃ©es
* le scraping
* l'application web

L'interface est ensuite accessible Ã  l'adresse :

```
http://127.0.0.1:8050
```

---

## RÃ©sultats et visualisation des donnÃ©es

### ï¸ Interface du dashboard

Le projet inclut un dashboard web interactif permettant d'explorer les donnÃ©es scrapÃ©es depuis Rotten Tomatoes.

Le dashboard constitue la seconde partie du projet aprÃ¨s le scraping.  
Il utilise les donnÃ©es stockÃ©es dans MongoDB pour gÃ©nÃ©rer des visualisations dynamiques accessibles via un navigateur.

---

## ï¸ Fonctionnement technique du dashboard

### Initialisation et configuration

Le script se connecte Ã  la mÃªme base de donnÃ©es MongoDB que celle utilisÃ©e par le scraper afin de rÃ©cupÃ©rer les films enregistrÃ©s.

---

### RÃ©cupÃ©ration des donnÃ©es

Les donnÃ©es sont chargÃ©es depuis la collection `movies` :

- titre  
- score critiques (Tomatometer)  
- score audience  
- URL du film  

Les films sont ensuite triÃ©s par score pour permettre l'analyse et l'affichage des meilleurs rÃ©sultats.

---

### CrÃ©ation des visualisations

Les graphiques sont gÃ©nÃ©rÃ©s cÃ´tÃ© front avec JavaScript / Plotly :

- Histogramme des scores Tomatometer  
- Histogramme des scores Audience  
- Distribution des notes  
- Top 10 des films les mieux notÃ©s  

---

### ï¸ Interface utilisateur

L'interface est organisÃ©e en onglets :

- Vue d'ensemble  
- Graphiques  
- Films  

Cela permet une navigation fluide entre les diffÃ©rentes analyses.

---

## ï¸ AperÃ§u du dashboard

### Analyse des distributions des scores

![Analyse des scores](docs/images/dashboard_overview.png)

---

### Top 10 des films

![Top 10 films](docs/images/dashboard_top10.png)

---

## ï¸ DifficultÃ©s rencontrÃ©es

L'une des principales difficultÃ©s a Ã©tÃ© liÃ©e au scraping du site Rotten Tomatoes.
Certaines informations ne sont pas directement visibles dans le HTML classique et sont intÃ©grÃ©es sous forme de donnÃ©es structurÃ©es. Il a fallu explorer la page en dÃ©tail pour trouver les bonnes variables Ã  extraire.

Un autre problÃ¨me important concernait la connexion entre les conteneurs Docker et MongoDB.
Au dÃ©part, l'application n'arrivait pas Ã  rÃ©cupÃ©rer les donnÃ©es car elle tentait de se connecter Ã  "localhost".
La solution a Ã©tÃ© d'utiliser le nom du service Docker ("mongo") comme adresse de connexion.

J'ai Ã©galement rencontrÃ© un souci oÃ¹ les donnÃ©es Ã©taient bien prÃ©sentes dans la base mais n'apparaissaient pas dans le dashboard.
Cela venait d'une mauvaise configuration de la connexion entre le backend Flask et MongoDB.

---

##  AmÃ©liorations possibles

Le projet pourrait Ãªtre enrichi de plusieurs faÃ§ons :

* ajouter des filtres par score
* scraper d'autres annÃ©es
* ajouter des statistiques comparatives plus avancÃ©es

---

##  Conclusion

Ce projet m'a permis de mettre en pratique plusieurs compÃ©tences importantes en data engineering :

* scraping de donnÃ©es web
* manipulation de bases NoSQL
* crÃ©ation d'API backend
* visualisation de donnÃ©es
* conteneurisation avec Docker

Il constitue une chaÃ®ne complÃ¨te de traitement de donnÃ©es, de la collecte jusqu'Ã  l'affichage.

---

## ğŸ‘¤ Auteur

**Lucas Wu**

- GitHub: [@LucasWu91](https://github.com/LucasWu91) 
- GitHub: [@DiegoT08](https://github.com/DiegoT08)
- Projet: [projet_rt_movies](https://github.com/LucasWu91/projet_rt_movies)

---

## ğŸ“ Licence

Ce projet a Ã©tÃ© rÃ©alisÃ© dans un cadre acadÃ©mique.
   
---

